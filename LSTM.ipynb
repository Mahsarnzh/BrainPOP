{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3ba0664-6159-4000-a4b3-21543f4bb91c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "e3ba0664-6159-4000-a4b3-21543f4bb91c",
    "outputId": "0dc63222-6957-4d8b-86cb-cc594ef361ce"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# Combine train and test datasets for tokenization\n",
    "combined_data = pd.concat([train_data, test_data])\n",
    "df = combined_data\n",
    "# Count the occurrences of each label\n",
    "label_counts = df['label'].value_counts()\n",
    "\n",
    "# Plot the bar chart\n",
    "plt.bar(label_counts.index, label_counts.values, color=['blue', 'orange'])\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Number of Entries for Each Label')\n",
    "plt.xticks(label_counts.index, ['Label 0', 'Label 1'])\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1204b767-1e60-4c12-8ee3-23c23db4652c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1204b767-1e60-4c12-8ee3-23c23db4652c",
    "outputId": "6a3423ac-8e72-4a9d-9045-f2e82d05732f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6388\n",
       "0    2690\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dc7e6f-2ac4-47f2-b807-d7cc63dd0632",
   "metadata": {
    "id": "00dc7e6f-2ac4-47f2-b807-d7cc63dd0632"
   },
   "source": [
    "### Using scaled Data input for LSTM model using MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74dad173-70cb-45fa-95c1-cdf31d590da4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74dad173-70cb-45fa-95c1-cdf31d590da4",
    "outputId": "291967a0-aa6b-4b1c-e816-824266497a42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "268/268 - 14s - loss: 0.6190 - accuracy: 0.7035 - 14s/epoch - 52ms/step\n",
      "Epoch 2/5\n",
      "268/268 - 10s - loss: 0.6135 - accuracy: 0.7044 - 10s/epoch - 38ms/step\n",
      "Epoch 3/5\n",
      "268/268 - 10s - loss: 0.6108 - accuracy: 0.7044 - 10s/epoch - 38ms/step\n",
      "Epoch 4/5\n",
      "268/268 - 9s - loss: 0.6132 - accuracy: 0.7044 - 9s/epoch - 35ms/step\n",
      "Epoch 5/5\n",
      "268/268 - 10s - loss: 0.6124 - accuracy: 0.7044 - 10s/epoch - 38ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7d3c3bf03370>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Load the train and test datasets\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# Combine train and test datasets for tokenization\n",
    "combined_data = pd.concat([train_data, test_data])\n",
    "\n",
    "# Tokenize and pad the sentences\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(combined_data['text'])\n",
    "\n",
    "# Tokenize and pad the train sentences\n",
    "train_sequences = tokenizer.texts_to_sequences(train_data['text'])\n",
    "train_padded_sequences = pad_sequences(train_sequences)\n",
    "\n",
    "# Tokenize and pad the test sentences\n",
    "test_sequences = tokenizer.texts_to_sequences(test_data['text'])\n",
    "test_padded_sequences = pad_sequences(test_sequences, maxlen=train_padded_sequences.shape[1])\n",
    "\n",
    "# Ensure the vocabulary size is the same for both train and test sets\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Use MinMaxScaler to scale the sequences\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Combine sequences for scaling\n",
    "combined_sequences = tokenizer.texts_to_sequences(combined_data['text'])\n",
    "combined_padded_sequences = pad_sequences(combined_sequences)\n",
    "combined_sequences_scaled = scaler.fit_transform(combined_padded_sequences)\n",
    "\n",
    "# Apply the same scaling to train and test sequences\n",
    "train_sequences_scaled = combined_sequences_scaled[:len(train_data)]\n",
    "test_sequences_scaled = combined_sequences_scaled[len(train_data):]\n",
    "\n",
    "# Pad the scaled sequences\n",
    "train_padded_sequences_scaled = pad_sequences(train_sequences_scaled)\n",
    "test_padded_sequences_scaled = pad_sequences(test_sequences_scaled, maxlen=train_padded_sequences_scaled.shape[1])\n",
    "\n",
    "# Define the neural network\n",
    "scaled_model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=64, input_length=train_padded_sequences_scaled.shape[1]),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    LSTM(32),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "scaled_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the scaled_model\n",
    "scaled_model.fit(train_padded_sequences_scaled, train_data['label'], epochs=5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ab96842-f5a0-4dfa-a0b1-e5c036daea98",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ab96842-f5a0-4dfa-a0b1-e5c036daea98",
    "outputId": "ed228191-0da3-483e-c802-f3a0999f2d8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 994ms/step\n",
      "The likelihood that the sentence is grammatically correct: 0.3241499066352844\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "class Grader:\n",
    "    def __init__(self, tokenizer, model, train_padded_sequences):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model = model\n",
    "        self.train_padded_sequences = train_padded_sequences\n",
    "\n",
    "    def evaluate_sentence(self, sentence):\n",
    "        input_sequence = pad_sequences(self.tokenizer.texts_to_sequences([sentence]), maxlen=self.train_padded_sequences.shape[1])\n",
    "        output_likelihood = self.model.predict(input_sequence)[0, 0]\n",
    "        grammatical_likelihood = 1 - output_likelihood\n",
    "        return grammatical_likelihood\n",
    "\n",
    "grader = Grader(tokenizer, scaled_model, train_padded_sequences)\n",
    "\n",
    "sentence_to_evaluate = \"he don't come here no more.\"\n",
    "likelihood = grader.evaluate_sentence(sentence_to_evaluate)\n",
    "\n",
    "print(f\"The likelihood that the sentence is grammatically correct: {likelihood}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d479e50-e814-4ea7-be9c-71a5e528252f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3d479e50-e814-4ea7-be9c-71a5e528252f",
    "outputId": "3cd0ae5f-6d9f-4906-ef63-e87edd5befcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 10ms/step\n",
      "Precision: 0.6925996204933587\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "predictions = scaled_model.predict(test_padded_sequences)\n",
    "binary_predictions = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Calculate precision and recall\n",
    "precision = precision_score(test_data['label'], binary_predictions)\n",
    "recall = recall_score(test_data['label'], binary_predictions)\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ea9053-20a1-4be2-9886-5f98dce2609a",
   "metadata": {
    "id": "e0ea9053-20a1-4be2-9886-5f98dce2609a"
   },
   "source": [
    "### Normal LSTM without any modifications to the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44148465-9c60-403c-8a1d-c552089a615a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "44148465-9c60-403c-8a1d-c552089a615a",
    "outputId": "be02a402-8a3c-4f41-e52c-ccdb823c3be3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "268/268 - 14s - loss: 0.6181 - accuracy: 0.7033 - 14s/epoch - 52ms/step\n",
      "Epoch 2/20\n",
      "268/268 - 10s - loss: 0.5895 - accuracy: 0.7099 - 10s/epoch - 38ms/step\n",
      "Epoch 3/20\n",
      "268/268 - 10s - loss: 0.5152 - accuracy: 0.7454 - 10s/epoch - 38ms/step\n",
      "Epoch 4/20\n",
      "268/268 - 10s - loss: 0.4527 - accuracy: 0.7750 - 10s/epoch - 38ms/step\n",
      "Epoch 5/20\n",
      "268/268 - 10s - loss: 0.3983 - accuracy: 0.8025 - 10s/epoch - 38ms/step\n",
      "Epoch 6/20\n",
      "268/268 - 11s - loss: 0.3556 - accuracy: 0.8213 - 11s/epoch - 40ms/step\n",
      "Epoch 7/20\n",
      "268/268 - 9s - loss: 0.3191 - accuracy: 0.8364 - 9s/epoch - 35ms/step\n",
      "Epoch 8/20\n",
      "268/268 - 10s - loss: 0.2894 - accuracy: 0.8496 - 10s/epoch - 38ms/step\n",
      "Epoch 9/20\n",
      "268/268 - 10s - loss: 0.2652 - accuracy: 0.8564 - 10s/epoch - 38ms/step\n",
      "Epoch 10/20\n",
      "268/268 - 10s - loss: 0.2385 - accuracy: 0.8660 - 10s/epoch - 39ms/step\n",
      "Epoch 11/20\n",
      "268/268 - 10s - loss: 0.2280 - accuracy: 0.8740 - 10s/epoch - 38ms/step\n",
      "Epoch 12/20\n",
      "268/268 - 10s - loss: 0.2126 - accuracy: 0.8827 - 10s/epoch - 35ms/step\n",
      "Epoch 13/20\n",
      "268/268 - 10s - loss: 0.2060 - accuracy: 0.8840 - 10s/epoch - 37ms/step\n",
      "Epoch 14/20\n",
      "268/268 - 10s - loss: 0.1866 - accuracy: 0.8929 - 10s/epoch - 38ms/step\n",
      "Epoch 15/20\n",
      "268/268 - 10s - loss: 0.1791 - accuracy: 0.8963 - 10s/epoch - 38ms/step\n",
      "Epoch 16/20\n",
      "268/268 - 10s - loss: 0.1721 - accuracy: 0.8990 - 10s/epoch - 38ms/step\n",
      "Epoch 17/20\n",
      "268/268 - 10s - loss: 0.1719 - accuracy: 0.8993 - 10s/epoch - 38ms/step\n",
      "Epoch 18/20\n",
      "268/268 - 9s - loss: 0.1697 - accuracy: 0.8970 - 9s/epoch - 35ms/step\n",
      "Epoch 19/20\n",
      "268/268 - 10s - loss: 0.1682 - accuracy: 0.9042 - 10s/epoch - 38ms/step\n",
      "Epoch 20/20\n",
      "268/268 - 10s - loss: 0.1615 - accuracy: 0.9034 - 10s/epoch - 38ms/step\n",
      "17/17 [==============================] - 1s 11ms/step - loss: 2.7178 - accuracy: 0.6300\n",
      "Test Accuracy: 0.6299810409545898\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the neural network\n",
    "bc_model = Sequential([\n",
    "    Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=64, input_length=train_padded_sequences.shape[1]),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    LSTM(32),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "bc_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the bc_model\n",
    "bc_model.fit(train_padded_sequences, train_data['label'], epochs=20, verbose=2)\n",
    "\n",
    "# Evaluate the bc_model on the test dataset\n",
    "test_loss, test_accuracy = bc_model.evaluate(test_padded_sequences, test_data['label'])\n",
    "print(f'Test Accuracy: {test_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2896000-eb07-4f67-9b24-2b9cba3096ce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a2896000-eb07-4f67-9b24-2b9cba3096ce",
    "outputId": "e83a9007-41a4-4c72-84f8-27364bd32f46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 727ms/step\n",
      "The likelihood that the sentence is grammatically correct: 1.0907649993896484e-05\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "sentence_to_evaluate = \"he don't come here no more.\"\n",
    "input_sequence = pad_sequences(tokenizer.texts_to_sequences([sentence_to_evaluate]), maxlen=train_padded_sequences.shape[1])\n",
    "\n",
    "output_likelihood = bc_model.predict(input_sequence)[0, 0]\n",
    "print(f\"The likelihood that the sentence is grammatically correct: {1- output_likelihood}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69426168-d81b-4aae-ac0a-76a40f1fe8eb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "69426168-d81b-4aae-ac0a-76a40f1fe8eb",
    "outputId": "da46d200-9485-4855-d718-dc7683c0b582"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "The likelihood that the sentence is grammatically correct: 1.0907649993896484e-05\n"
     ]
    }
   ],
   "source": [
    "grader = Grader(tokenizer, bc_model, train_padded_sequences)\n",
    "\n",
    "sentence_to_evaluate = \"he don't come here no more.\"\n",
    "likelihood = grader.evaluate_sentence(sentence_to_evaluate)\n",
    "\n",
    "print(f\"The likelihood that the sentence is grammatically correct: {likelihood}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca77ff1c-d0ea-4b5b-8f96-5e65f293a8b7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ca77ff1c-d0ea-4b5b-8f96-5e65f293a8b7",
    "outputId": "d5923ce8-4399-49a6-9ae3-56a0da4cc6f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 11ms/step\n",
      "Precision: 0.7146464646464646\n",
      "Recall: 0.7753424657534247\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "predictions = bc_model.predict(test_padded_sequences)\n",
    "binary_predictions = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Calculate precision and recall\n",
    "precision = precision_score(test_data['label'], binary_predictions)\n",
    "recall = recall_score(test_data['label'], binary_predictions)\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f508d40f-67f1-42bf-a5c3-6eb6a9fc6214",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f508d40f-67f1-42bf-a5c3-6eb6a9fc6214",
    "outputId": "437a31e5-c955-43c0-b9ab-558f4873ca67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 10ms/step - loss: 0.6258 - accuracy: 0.6850\n",
      "Test Accuracy: 0.6850094795227051\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "test_loss, test_accuracy = bc_model.evaluate(test_padded_sequences_scaled, test_data['label'])\n",
    "print(f'Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fd81b6-84e4-471c-b297-55a5b86c6a15",
   "metadata": {
    "id": "d7fd81b6-84e4-471c-b297-55a5b86c6a15"
   },
   "source": [
    "### Using SMOTE to over sample the minority class which is label 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "950ab9f7-6b0b-4aed-9265-bd5e2f453fb6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "950ab9f7-6b0b-4aed-9265-bd5e2f453fb6",
    "outputId": "3910828d-48b8-42c5-aead-c7f71e8d464b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "377/377 - 18s - loss: 0.2502 - accuracy: 0.4979 - 18s/epoch - 49ms/step\n",
      "Epoch 2/5\n",
      "377/377 - 14s - loss: 0.2501 - accuracy: 0.4936 - 14s/epoch - 37ms/step\n",
      "Epoch 3/5\n",
      "377/377 - 14s - loss: 0.2500 - accuracy: 0.4988 - 14s/epoch - 37ms/step\n",
      "Epoch 4/5\n",
      "377/377 - 14s - loss: 0.2500 - accuracy: 0.4866 - 14s/epoch - 37ms/step\n",
      "Epoch 5/5\n",
      "377/377 - 32s - loss: 0.2500 - accuracy: 0.4987 - 32s/epoch - 85ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7d3c379925c0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Ensure the vocabulary size is the same for both train and test sets\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Use MinMaxScaler to scale the sequences\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Apply the same scaling to train and test sequences separately\n",
    "train_sequences_scaled = scaler.fit_transform(train_padded_sequences)\n",
    "test_sequences_scaled = scaler.transform(test_padded_sequences)\n",
    "\n",
    "# Apply SMOTE to over-sample the minority class on the training data\n",
    "oversampler = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = oversampler.fit_resample(train_sequences_scaled, train_data['label'])\n",
    "\n",
    "# Define the neural network\n",
    "SMOTE_model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=64, input_length=X_resampled.shape[1]),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    LSTM(32),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "SMOTE_model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "# Train the SMOTE_model\n",
    "SMOTE_model.fit(X_resampled, y_resampled, epochs=5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2568d4ba-1a96-4fdb-a030-0c76e1b2647d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2568d4ba-1a96-4fdb-a030-0c76e1b2647d",
    "outputId": "22ae372c-aed5-4b0d-8217-1bc370144bf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 737ms/step\n",
      "The likelihood that the sentence is grammatically correct: 0.5003257393836975\n"
     ]
    }
   ],
   "source": [
    "grader = Grader(tokenizer, SMOTE_model, train_padded_sequences)\n",
    "\n",
    "sentence_to_evaluate = \"he don't come here no more.\"\n",
    "likelihood = grader.evaluate_sentence(sentence_to_evaluate)\n",
    "\n",
    "print(f\"The likelihood that the sentence is grammatically correct: {likelihood}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff2c2240-877b-44cc-b8fc-396c4b9adb71",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ff2c2240-877b-44cc-b8fc-396c4b9adb71",
    "outputId": "ca21224e-1f2c-413b-98a1-16503914c469"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 11ms/step\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "predictions = SMOTE_model.predict(test_padded_sequences)\n",
    "binary_predictions = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Calculate precision and recall\n",
    "precision = precision_score(test_data['label'], binary_predictions)\n",
    "recall = recall_score(test_data['label'], binary_predictions)\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53990001-5697-41c1-ab97-ae7898e4a095",
   "metadata": {
    "id": "53990001-5697-41c1-ab97-ae7898e4a095"
   },
   "source": [
    "### No changes to the input but using MSE for loss value calculation instead of binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24e78630-0e94-4384-9b60-27c75764c98f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24e78630-0e94-4384-9b60-27c75764c98f",
    "outputId": "ad2337f2-76f9-42d1-92df-835f44f33de3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "268/268 - 21s - loss: 0.2137 - accuracy: 0.7041 - 21s/epoch - 78ms/step\n",
      "Epoch 2/20\n",
      "268/268 - 11s - loss: 0.1965 - accuracy: 0.7124 - 11s/epoch - 40ms/step\n",
      "Epoch 3/20\n",
      "268/268 - 16s - loss: 0.1668 - accuracy: 0.7531 - 16s/epoch - 58ms/step\n",
      "Epoch 4/20\n",
      "268/268 - 10s - loss: 0.1445 - accuracy: 0.7889 - 10s/epoch - 37ms/step\n",
      "Epoch 5/20\n",
      "268/268 - 10s - loss: 0.1298 - accuracy: 0.8158 - 10s/epoch - 39ms/step\n",
      "Epoch 6/20\n",
      "268/268 - 10s - loss: 0.1168 - accuracy: 0.8381 - 10s/epoch - 39ms/step\n",
      "Epoch 7/20\n",
      "268/268 - 10s - loss: 0.1079 - accuracy: 0.8498 - 10s/epoch - 39ms/step\n",
      "Epoch 8/20\n",
      "268/268 - 12s - loss: 0.0986 - accuracy: 0.8583 - 12s/epoch - 46ms/step\n",
      "Epoch 9/20\n",
      "268/268 - 18s - loss: 0.0899 - accuracy: 0.8688 - 18s/epoch - 67ms/step\n",
      "Epoch 10/20\n",
      "268/268 - 14s - loss: 0.0846 - accuracy: 0.8759 - 14s/epoch - 53ms/step\n",
      "Epoch 11/20\n",
      "268/268 - 10s - loss: 0.0769 - accuracy: 0.8861 - 10s/epoch - 37ms/step\n",
      "Epoch 12/20\n",
      "268/268 - 14s - loss: 0.0733 - accuracy: 0.8905 - 14s/epoch - 51ms/step\n",
      "Epoch 13/20\n",
      "268/268 - 10s - loss: 0.0711 - accuracy: 0.8910 - 10s/epoch - 38ms/step\n",
      "Epoch 14/20\n",
      "268/268 - 13s - loss: 0.0670 - accuracy: 0.8976 - 13s/epoch - 49ms/step\n",
      "Epoch 15/20\n",
      "268/268 - 14s - loss: 0.0643 - accuracy: 0.9004 - 14s/epoch - 53ms/step\n",
      "Epoch 16/20\n",
      "268/268 - 10s - loss: 0.0628 - accuracy: 0.9026 - 10s/epoch - 39ms/step\n",
      "Epoch 17/20\n",
      "268/268 - 10s - loss: 0.0607 - accuracy: 0.9076 - 10s/epoch - 38ms/step\n",
      "Epoch 18/20\n",
      "268/268 - 10s - loss: 0.0576 - accuracy: 0.9094 - 10s/epoch - 39ms/step\n",
      "Epoch 19/20\n",
      "268/268 - 10s - loss: 0.0554 - accuracy: 0.9140 - 10s/epoch - 38ms/step\n",
      "Epoch 20/20\n",
      "268/268 - 10s - loss: 0.0542 - accuracy: 0.9153 - 10s/epoch - 38ms/step\n",
      "17/17 [==============================] - 3s 17ms/step - loss: 0.3367 - accuracy: 0.6224\n",
      "Test Accuracy: 0.622390866279602\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the neural network\n",
    "MSE_model = Sequential([\n",
    "    Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=64, input_length=train_padded_sequences.shape[1]),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    LSTM(32),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "MSE_model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "# Train the MSE_model\n",
    "MSE_model.fit(train_padded_sequences, train_data['label'], epochs=20, verbose=2)\n",
    "\n",
    "# Evaluate the MSE_model on the test dataset\n",
    "test_loss, test_accuracy = MSE_model.evaluate(test_padded_sequences, test_data['label'])\n",
    "print(f'Test Accuracy: {test_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87b89d51-a358-4fea-b9f4-86dad78a4516",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "87b89d51-a358-4fea-b9f4-86dad78a4516",
    "outputId": "86030359-1c0b-49c2-c5f0-b6573a2487d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 951ms/step\n",
      "The likelihood that the sentence is grammatically correct: 1.3113021850585938e-06\n"
     ]
    }
   ],
   "source": [
    "grader = Grader(tokenizer, MSE_model, train_padded_sequences)\n",
    "\n",
    "sentence_to_evaluate = \"he don't come here no more.\"\n",
    "likelihood = grader.evaluate_sentence(sentence_to_evaluate)\n",
    "\n",
    "print(f\"The likelihood that the sentence is grammatically correct: {likelihood}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74499bb5-2b80-4fbe-9093-0d1d0b02e797",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74499bb5-2b80-4fbe-9093-0d1d0b02e797",
    "outputId": "cefe844a-89fb-476f-ef81-d04aa6ab80e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 10ms/step\n",
      "Precision: 0.7064676616915423\n",
      "Recall: 0.7780821917808219\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "predictions = MSE_model.predict(test_padded_sequences)\n",
    "binary_predictions = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Calculate precision and recall\n",
    "precision = precision_score(test_data['label'], binary_predictions)\n",
    "recall = recall_score(test_data['label'], binary_predictions)\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4dc2d1-feac-4d0b-ad4b-95ee41afbe99",
   "metadata": {
    "id": "0a4dc2d1-feac-4d0b-ad4b-95ee41afbe99"
   },
   "source": [
    "### Applying Random Over-Sampling to over-sample the minority class (label 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b00599c5-c597-4bb3-940b-141d51bfa6d9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b00599c5-c597-4bb3-940b-141d51bfa6d9",
    "outputId": "76b09849-9263-4b33-f18f-4ad9cbfc88f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "377/377 - 18s - loss: 0.2502 - accuracy: 0.4892 - 18s/epoch - 47ms/step\n",
      "Epoch 2/5\n",
      "377/377 - 14s - loss: 0.2500 - accuracy: 0.4949 - 14s/epoch - 38ms/step\n",
      "Epoch 3/5\n",
      "377/377 - 15s - loss: 0.2500 - accuracy: 0.5017 - 15s/epoch - 40ms/step\n",
      "Epoch 4/5\n",
      "377/377 - 14s - loss: 0.2500 - accuracy: 0.4987 - 14s/epoch - 38ms/step\n",
      "Epoch 5/5\n",
      "377/377 - 14s - loss: 0.2500 - accuracy: 0.4980 - 14s/epoch - 37ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7d3c4b56a680>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Ensure the vocabulary size is the same for both train and test sets\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Use MinMaxScaler to scale the sequences\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Combine sequences for scaling\n",
    "combined_sequences = tokenizer.texts_to_sequences(combined_data['text'])\n",
    "combined_padded_sequences = pad_sequences(combined_sequences)\n",
    "combined_sequences_scaled = scaler.fit_transform(combined_padded_sequences)\n",
    "\n",
    "# Apply the same scaling to train and test sequences\n",
    "train_sequences_scaled = combined_sequences_scaled[:len(train_data)]\n",
    "test_sequences_scaled = combined_sequences_scaled[len(train_data):]\n",
    "\n",
    "# Pad the scaled sequences\n",
    "train_padded_sequences_scaled = pad_sequences(train_sequences_scaled)\n",
    "test_padded_sequences_scaled = pad_sequences(test_sequences_scaled, maxlen=train_padded_sequences_scaled.shape[1])\n",
    "\n",
    "# Apply Random Over-Sampling to over-sample the minority class (label 0)\n",
    "oversampler = RandomOverSampler(sampling_strategy='minority')\n",
    "X_resampled, y_resampled = oversampler.fit_resample(train_padded_sequences_scaled, train_data['label'])\n",
    "\n",
    "# Define the neural network\n",
    "ROS_model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=64, input_length=X_resampled.shape[1]),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    LSTM(32),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "ROS_model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "# Train the ROS_model\n",
    "ROS_model.fit(X_resampled, y_resampled, epochs=5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16c34e9c-00cf-4644-9fb1-28189018a5ac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "16c34e9c-00cf-4644-9fb1-28189018a5ac",
    "outputId": "c16f9d96-3f56-4621-989b-347d23a94301"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 745ms/step\n",
      "The likelihood that the sentence is grammatically correct: 0.5004397630691528\n"
     ]
    }
   ],
   "source": [
    "grader = Grader(tokenizer, ROS_model, train_padded_sequences)\n",
    "\n",
    "sentence_to_evaluate = \"he don't come here no more.\"\n",
    "likelihood = grader.evaluate_sentence(sentence_to_evaluate)\n",
    "\n",
    "print(f\"The likelihood that the sentence is grammatically correct: {likelihood}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25f53cd5-6f77-4b0d-b1f6-6d699aed689e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "25f53cd5-6f77-4b0d-b1f6-6d699aed689e",
    "outputId": "6a6f1335-8e47-4187-83fc-b18be1704422"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 10ms/step\n",
      "Precision: 1.0\n",
      "Recall: 0.0027397260273972603\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "predictions = ROS_model.predict(test_padded_sequences)\n",
    "binary_predictions = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Calculate precision and recall\n",
    "precision = precision_score(test_data['label'], binary_predictions)\n",
    "recall = recall_score(test_data['label'], binary_predictions)\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676afd0c-b24d-4a31-9a4d-38f979627f1c",
   "metadata": {
    "id": "676afd0c-b24d-4a31-9a4d-38f979627f1c"
   },
   "source": [
    "### Applying Random Under-Sampling to under-sample the majority class (label 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01d33d7d-550b-46cd-8d67-bb0898a2d3ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "01d33d7d-550b-46cd-8d67-bb0898a2d3ee",
    "outputId": "db500783-3c05-4522-f970-d66cd00261a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "158/158 - 9s - loss: 0.6940 - accuracy: 0.4968 - 9s/epoch - 56ms/step\n",
      "Epoch 2/5\n",
      "158/158 - 5s - loss: 0.6934 - accuracy: 0.5063 - 5s/epoch - 30ms/step\n",
      "Epoch 3/5\n",
      "158/158 - 6s - loss: 0.6935 - accuracy: 0.5061 - 6s/epoch - 35ms/step\n",
      "Epoch 4/5\n",
      "158/158 - 5s - loss: 0.6933 - accuracy: 0.5059 - 5s/epoch - 30ms/step\n",
      "Epoch 5/5\n",
      "158/158 - 6s - loss: 0.6933 - accuracy: 0.5018 - 6s/epoch - 39ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7d3c38edc3a0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Ensure the vocabulary size is the same for both train and test sets\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Use MinMaxScaler to scale the sequences\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Combine sequences for scaling\n",
    "combined_sequences = tokenizer.texts_to_sequences(combined_data['text'])\n",
    "combined_padded_sequences = pad_sequences(combined_sequences)\n",
    "combined_sequences_scaled = scaler.fit_transform(combined_padded_sequences)\n",
    "\n",
    "# Apply the same scaling to train and test sequences\n",
    "train_sequences_scaled = combined_sequences_scaled[:len(train_data)]\n",
    "test_sequences_scaled = combined_sequences_scaled[len(train_data):]\n",
    "\n",
    "# Pad the scaled sequences\n",
    "train_padded_sequences_scaled = pad_sequences(train_sequences_scaled)\n",
    "test_padded_sequences_scaled = pad_sequences(test_sequences_scaled, maxlen=train_padded_sequences_scaled.shape[1])\n",
    "\n",
    "# Apply Random Under-Sampling to under-sample the majority class (label 1)\n",
    "undersampler = RandomUnderSampler(sampling_strategy='majority')\n",
    "X_resampled, y_resampled = undersampler.fit_resample(train_padded_sequences_scaled, train_data['label'])\n",
    "\n",
    "# Define the neural network\n",
    "RUS_model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=64, input_length=X_resampled.shape[1]),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    LSTM(32),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "RUS_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the RUS_model\n",
    "RUS_model.fit(X_resampled, y_resampled, epochs=5, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c62dbf0-f2b6-461f-a5bf-e9b972d44520",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7c62dbf0-f2b6-461f-a5bf-e9b972d44520",
    "outputId": "3082ea71-7b43-4c80-b7ee-4113b8bc8c44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 744ms/step\n",
      "The likelihood that the sentence is grammatically correct: 0.5001298785209656\n"
     ]
    }
   ],
   "source": [
    "grader = Grader(tokenizer, RUS_model, train_padded_sequences)\n",
    "\n",
    "sentence_to_evaluate = \"he don't come here no more.\"\n",
    "likelihood = grader.evaluate_sentence(sentence_to_evaluate)\n",
    "\n",
    "print(f\"The likelihood that the sentence is grammatically correct: {likelihood}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76086c0b-ce25-4d77-bfea-19724946e5ac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "76086c0b-ce25-4d77-bfea-19724946e5ac",
    "outputId": "9002228a-8563-4649-d97b-21202bb1e2ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 11ms/step\n",
      "Precision: 0.69375\n",
      "Recall: 0.9123287671232877\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "predictions = RUS_model.predict(test_padded_sequences)\n",
    "binary_predictions = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Calculate precision and recall\n",
    "precision = precision_score(test_data['label'], binary_predictions)\n",
    "recall = recall_score(test_data['label'], binary_predictions)\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "z7DDFhJd-jNI",
   "metadata": {
    "id": "z7DDFhJd-jNI"
   },
   "source": [
    "# As evident from the results, based on playing around with the grader class the models perform better when the input data is left unscaled, showcasing superior outcomes compared to instances where input data undergoes scaling or balancing. However, based on precision and recall, the output of the scaled data using minmaxscaler showed superior results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4DeClxIoL7JA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4DeClxIoL7JA",
    "outputId": "5f253556-7af0-40e2-d6a9-4a856c0234ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "based on RUS_model the likelihood that the sentence is grammatically correct: 0.5001298785209656\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "based on ROS_model the likelihood that the sentence is grammatically correct: 0.5004397630691528\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "based on MSE_model the likelihood that the sentence is grammatically correct: 1.3113021850585938e-06\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "based on SMOTE_model the likelihood that the sentence is grammatically correct: 0.5003257393836975\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "based on bc_model the likelihood that the sentence is grammatically correct: 1.0907649993896484e-05\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "based on scaled_model the likelihood that the sentence is grammatically correct: 0.3241499066352844\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"RUS_model\": RUS_model,\n",
    "    \"ROS_model\": ROS_model,\n",
    "    \"MSE_model\": MSE_model,\n",
    "    \"SMOTE_model\": SMOTE_model,\n",
    "    \"bc_model\": bc_model,\n",
    "    \"scaled_model\": scaled_model\n",
    "}\n",
    "\n",
    "sentence_to_evaluate = \"he don't come here no more.\"\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    grader = Grader(tokenizer, model, train_padded_sequences)\n",
    "    likelihood = grader.evaluate_sentence(sentence_to_evaluate)\n",
    "    print(f\"based on {model_name} the likelihood that the sentence is grammatically correct: {likelihood}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bLXw9c3dNWi8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bLXw9c3dNWi8",
    "outputId": "a38d60ff-8493-4669-94a9-3e6bfef0cce4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n",
      "based on RUS_model the likelihood that the sentence is grammatically correct: 0.5001730918884277\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "based on ROS_model the likelihood that the sentence is grammatically correct: 0.5004723072052002\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "based on MSE_model the likelihood that the sentence is grammatically correct: 0.9999995941060433\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "based on SMOTE_model the likelihood that the sentence is grammatically correct: 0.5004700720310211\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "based on bc_model the likelihood that the sentence is grammatically correct: 0.999999981634323\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "based on scaled_model the likelihood that the sentence is grammatically correct: 0.3241214156150818\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"RUS_model\": RUS_model,\n",
    "    \"ROS_model\": ROS_model,\n",
    "    \"MSE_model\": MSE_model,\n",
    "    \"SMOTE_model\": SMOTE_model,\n",
    "    \"bc_model\": bc_model,\n",
    "    \"scaled_model\": scaled_model\n",
    "}\n",
    "\n",
    "sentence_to_evaluate = \"he doesn't come here any more.\"\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    grader = Grader(tokenizer, model, train_padded_sequences)\n",
    "    likelihood = grader.evaluate_sentence(sentence_to_evaluate)\n",
    "    print(f\"based on {model_name} the likelihood that the sentence is grammatically correct: {likelihood}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yd1pUdX7QEsp",
   "metadata": {
    "id": "yd1pUdX7QEsp"
   },
   "source": [
    "# To improve the performance of the LSTM model, I woul consider the following methods:\n",
    "\n",
    "## Experiment with Model Architecture:\n",
    "\n",
    "- I would adjust the number of LSTM layers and units to see if a deeper or wider network improves performance.\n",
    "- I would also try different activation functions in the Dense layers.\n",
    "- Or I would consider using bidirectional LSTM layers to capture information from both past and future sequences.\n",
    "\n",
    "## Embedding Layer Parameters:\n",
    "\n",
    "- I would experiment with different values for the `output_dim` parameter in the Embedding layer.\n",
    "- I would tune the `input_length` parameter based on the average length of the input sequences.\n",
    "\n",
    "## Adjust Dropout Rate:\n",
    "\n",
    "- The dropout rate in the Dropout layer can be adjusted.  I would experiment with different rates to prevent overfitting.\n",
    "\n",
    "## Learning Rate and Optimizer:\n",
    "\n",
    "- Adjusting the learning rate of the optimizer (adam in this case) might be helpfull. A smaller learning rate might help in convergence.\n",
    "- Experiment with different optimizers, such as RMSprop or SGD.\n",
    "\n",
    "\n",
    "## Sequence Padding:\n",
    "\n",
    "- Experimenting with different padding strategies might be helpful. I would try pre-padding or post-padding and observe the impact on model performance.\n",
    "\n",
    "## Regularization Techniques:\n",
    "\n",
    "- I would consider adding L2 regularization to the LSTM and Dense layers to prevent overfitting.\n",
    "- I would experiment with different dropout rates or try other regularization techniques.\n",
    "\n",
    "## Hyperparameter Tuning:\n",
    "\n",
    "- I would use techniques like grid search or random search to find the optimal combination of hyperparameters.\n",
    "\n",
    "\n",
    "## Increase Training Data:\n",
    "\n",
    "- I would try to increase the size of the training dataset to provide the model with more diverse examples.\n",
    "\n",
    "If I had more time I would monitor the model's performance after each modification using mlflow and keep track of changes that positively impact performance. It's often beneficial to iteratively experiment and fine-tune to achieve the best results."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
